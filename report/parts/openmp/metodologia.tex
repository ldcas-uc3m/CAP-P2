\section{Metodología del paralelismo}
% Aquí debemos incluir la metodología seguida recogiendo donde hemos aplicado paralelismo así como en los distintos puntos siguiendo las etapas recogidas en el enunciado.
La metodología de paralelización aplicada se desarrolla siguiendo las cuatro fases clave presentadas en el enunciado de la práctica: descomposición, asignación, orquestación y reparto. Estas fases permiten establecer una dinámica de trabajo para transformar un conjunto de operaciones secuenciales en un código paralelizado eficiente y escalable, aprovechando al máximo los recursos disponibles. A continuación, se incluye la implementación de estas fases en los puntos críticos, previamente identificados, utilizando \textbf{OpenMP}.

En la fase de \textbf{descomposición}, el objetivo principal es identificar las tareas que pueden ejecutarse de forma concurrente. Esto se ha logrado aislando las operaciones repetitivas que trabajan de forma independiente sobre píxeles o datos individuales. Por ejemplo, en las funciones de lectura y escritura de imágenes (\texttt{read\_ppm()} y \texttt{write\_ppm()}, caso 1 y 2 de ahora en adelante), cada iteración del bucle procesa un píxel independiente, separando o combinando los canales RGB en sus respectivas estructuras de datos. Se han observado operaciones independientes y similares a casos anteriores entre píxeles en las transformaciones de color RGB a HSL y viceversa (\texttt{rgb2hsl()} y \texttt{hsl2rgb()}, caso 3 y 4 de ahora en adelante), así como en las conversiones entre los espacios de color RGB y YCbCr (\texttt{rgb2yuv()} y \texttt{yuv2rgb()}, caso 5 y 6 de ahora en adelante). En estos casos, cada repetición aplica cálculos matemáticos que no dependen de los resultados de otras iteraciones, lo que permite una descomposición natural a nivel de píxel.
Adicionalmente, se incluyen procesos más complejos como el cálculo de histogramas (\texttt{histogram()}, de ahora en adelante caso 7), donde la descomposición implica dividir los píxeles entre los hilos y acumular los resultados en histogramas locales. Finalmente, en operaciones de reducción como la búsqueda del mínimo no nulo en un histograma (\texttt{histogram\_equalization()}, caso 8 de ahora en adelante) y las transformaciones basadas en una tabla de búsqueda (\texttt{histogram\_equalization()}, caso 9 de ahora en adelante), la descomposición se ha realizado a nivel de elementos individuales, como valores del histograma o píxeles.

Una vez identificadas las tareas, se procede a la fase de \textbf{asignación}, distribuyendo las cargas de trabajo entre los recursos disponibles utilizando hilos. En la mayoría de los casos, como en las operaciones de lectura, escritura y conversiones de color, se ha empleado la directiva \texttt{\#pragma omp parallel for} para repartir las iteraciones de los bucles entre los hilos de forma automática, aunque para las métricas posteriores se controla su reparto con fines educativos. Esta aproximación resulta eficiente debido a la homogeneidad de las operaciones en cada repetición. Para tareas más específicas, como el cálculo de histogramas, caso 7, se asignan bloques de píxeles a cada hilo, generando histogramas parciales que posteriormente se combinaron. En la búsqueda del mínimo del histograma, caso 8, se permite que los hilos trabajen en diferentes rangos del histograma, con le objetivo de asegurar una cobertura completa del espacio de datos.

La \textbf{orquestación} es la próxima etapa, crucial para garantizar que los hilos trabajen de manera coordinada y así evitar conflictos. En tareas completamente independientes, como las transformaciones de píxeles (casos 1-6 y 9), no es necesario emplear sincronización adicional. Sin embargo, en procesos como el cálculo de histogramas (casos 7, 8 y 9), donde múltiples hilos actualizan un resultado global, se han introducido secciones críticas, \texttt{\#pragma omp critical}, para combinar los histogramas parciales en un único histograma global. Esta sincronización también se utiliza en la búsqueda del mínimo en el histograma, caso 8, donde una sección crítica permite asegurar que la variable compartida \texttt{min} se actualice de manera coherente, sin dar lugar a problemas típicos de memoria compartida.

Por último, en la fase de \textbf{reparto}, es vital definir cómo distribuir las tareas de manera eficiente. Para la mayoría de las operaciones homogéneas, en los casos 1-6 y 9, se opta por un reparto estático \texttt{schedule(static)}, dividiendo equitativamente las iteraciones entre los hilos para minimizar una posible sobrecarga en el planificador del procesador. En mayor detalle, a destacar un caso particular en la conversión de YUV a RGB, donde el tamaño de \textit{chunk} se ha establecido en 64 bloques, deducidos del tamaño de la imagen, resultando en una planificación estática ajustada \texttt{schedule(static, 64)} otorgando mejores resultados. 
En el cálculo de histogramas, el reparto es implícito, dado que cada hilo procesa un subconjunto de píxeles. En aquellos procesos donde la carga de trabajo puede variar dinámicamente, como la búsqueda del mínimo no nulo en el histograma, la implementación incluye un punto de sincronización adicional, aunque no requiere un reparto explícito debido a la naturaleza del problema.

En conjunto, esta metodología permite identificar, asignar, orquestar y repartir el trabajo de forma paralela en puntos clave del programa, logrando una ejecución más eficiente sin comprometer la precisión de los resultados. Las decisiones tomadas en cada fase aseguran un balance adecuado entre simplicidad, rendimiento y escalabilidad.